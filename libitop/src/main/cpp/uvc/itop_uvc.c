/* DO NOT EDIT THIS FILE - it is machine generated */
#include <errno.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <sys/ioctl.h>
#include <unistd.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <asm/types.h>
#include <linux/videodev2.h>
#include <sys/mman.h>
#include <string.h>
#include <malloc.h>
#include <linux/fb.h>
#include <jni.h>
#include <syslog.h>
#include <android/log.h>

#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libswscale/swscale.h"
#include "itop_uvc.h"

#define  LOG_TAG    "ITOP_UVC"
#define LOGV(...) __android_log_print(ANDROID_LOG_VERBOSE, LOG_TAG, __VA_ARGS__)
#define LOGD(...) __android_log_print(ANDROID_LOG_DEBUG  , LOG_TAG, __VA_ARGS__)
#define LOGI(...) __android_log_print(ANDROID_LOG_INFO   , LOG_TAG, __VA_ARGS__)
#define LOGW(...) __android_log_print(ANDROID_LOG_WARN   , LOG_TAG, __VA_ARGS__)
#define LOGE(...) __android_log_print(ANDROID_LOG_ERROR  , LOG_TAG, __VA_ARGS__)

struct fimc_buffer {
    unsigned char *start;
    size_t length;
};

/******
 * V4L2(Video For Linux Two) 是内核提供给应用程序访问音、视频驱动的统一接口。V4L2 的相关定义包含在头文件<linux/videodev2.h> 中.
 * ******/

static int fd = -1;
struct fimc_buffer *buffers = NULL;

/**
 * struct v4l2_buffer
 * {
 *     u32 index;//buffer 序号
 *     enum v4l2_buf_type type; //buffer 类型
 *     u32 byteused;//buffer 中已使用的字节数
 *     u32 flags;// 区分是MMAP 还是USERPTR
 *     enum v4l2_field field;
 *     struct timeval timestamp; // 获取第一个字节时的系统时间
 *     struct v4l2_timecode timecode;
 *     u32 sequence;// 队列中的序号
 *     enum v4l2_memory memory; //IO 方式，被应用程序设置
 *     union m
 *     {
 *         u32 offset;// 缓冲帧地址，只对MMAP 有效
 *         unsignedlong userptr;
 *     };
 *     u32 length;// 缓冲帧长度
 *     u32 input;
 *     u32 reserved;
 * };
 */
struct v4l2_buffer v4l2_buf;
static int bufnum = 1;
static int mwidth, mheight;

/* Header for class com_jiangyt_library_libitop_UvcCamera */
#undef TCSAFLUSH
#define TCSAFLUSH TCSETSF
#ifndef _TERMIOS_H_
#define _TERMIOS_H_
#endif
/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    open
 * Signature: (I)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_open
        (JNIEnv *env, jclass obj, jint devid) {
    char *devname;
    switch (devid) {
        case 0:
            devname = "/dev/video0";
            break;
        case 1:
            devname = "/dev/video1";
            break;
        case 2:
            devname = "/dev/video2";
            break;
        case 3:
            devname = "/dev/video3";
            break;
        default:
            devname = "/dev/video4";
            break;
    }
    // 打开设备(fcntl.h) uvc摄像头，插入后对应生成"/dev/video4"
    fd = open(devname, O_RDWR);

    if (fd < 0)
        LOGE("%s ++++ open error\n", devname);
    return fd;
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    init
 * Signature: (III)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_init
        (JNIEnv *env, jclass obj, jint width, jint height, jint numbuf) {
    int ret;
    int i;
    bufnum = numbuf;
    mwidth = width;
    mheight = height;
    /**
     * 用来设置摄像头的视频格式、帧格式等
     * 在设置这个参数时应先填 好 v4l2_format 的各个域，如
     * type（传输流类型），
     * fmt.pix.width(宽)，
     * fmt.pix.heigth(高)，
     * fmt.pix.field(采样区域，如隔行采样)，
     * fmt.pix.pixelformat(采样类型，如 YUV4:2:2)
     * ，然后通过 VIDIO_S_FMT 操作命令设置视频捕捉格式
     *
     * v4l2_buf_type type; // 帧类型，应用程序设置
     * struct v4l2_pix_format pix; // 视频设备使用
     */
    struct v4l2_format fmt;
    /**
     * 获取设备属性
     * u8 driver[16]; // 驱动名字
     * u8 card[32]; // 设备名字
     * u8 bus_info[32]; // 设备在系统中的位置
     * u32 version;// 驱动版本号
     * u32 capabilities;// 设备支持的操作
     * u32 device_caps; //
     * u32 reserved[4]; // 保留字段
     */
    struct v4l2_capability cap;

    // 查询设备属性 VIDIOC_QUERYCAP
    ret = ioctl(fd, VIDIOC_QUERYCAP, &cap);
    if (ret < 0) {
        LOGE("%d :VIDIOC_QUERYCAP failed\n", __LINE__);
        return -1;
    }
    //printf("Driver Name:%s\nCard Name:%s\nBus info:%s\nDriver Version:%u.%u.%u\n",cap.driver,cap.card,cap.bus_info,cap.capabilities);
    // capabilities 常用值:
    // V4L2_CAP_VIDEO_CAPTURE // 是否支持图像获取
    if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE)) {
        LOGE("%d : no capture devices\n", __LINE__);
        return -1;
    }

    // 将某一块内存中的内容全部设置为指定的值， 这个函数通常为新申请的内存做初始化工作。
    memset(&fmt, 0, sizeof(fmt));
    // 设置传输流类型
    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    // 设置采样类型
    fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
    fmt.fmt.pix.width = width;
    fmt.fmt.pix.height = height;
    // 设置当前格式为：视频捕捉格式
    if (ioctl(fd, VIDIOC_S_FMT, &fmt) < 0) {
        LOGE("++++%d : set format failed\n", __LINE__);
        return -1;
    }

    /**
     * u32 count;// 缓冲区内缓冲帧的数目
     * enum v4l2_buf_type type; // 缓冲帧数据格式
     * enum v4l2_memory memory; // 区别是内存映射还是用户指针方式
     *                          // V4L2_MEMORY_MMAP, V4L2_MEMORY_USERPTR
     * u32 reserved[2];
     */
    struct v4l2_requestbuffers req;
    req.count = numbuf;
    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    req.memory = V4L2_MEMORY_MMAP;

    //ioctl是设备驱动程序中对设备的I/O通道进行管理的函数。所谓对I/O通道进行管理，就是对设备的一些特性进行控制
    /**
     * fd open 函数返回的文件标识符
     * request 用户程序对设备的控制命令
     * 后面参数，是补充参数，一般最多一个，这个参数的有无和cmd的意义相关。
     */
    ret = ioctl(fd, VIDIOC_REQBUFS, &req);
    if (ret < 0) {
        LOGE("++++%d : VIDIOC_REQBUFS failed\n", __LINE__);
        return -1;
    }

    /**
     * 分配所需的内存空间，并返回一个指向它的指针，指向已分配的内存
     * item_count -- 要被分配的元素个数。
     * item_size -- 元素的大小。
     */
    buffers = calloc(req.count, sizeof(*buffers));
    if (!buffers) {
        LOGE ("++++%d Out of memory\n", __LINE__);
        return -1;
    }

    // 初始化v4l2 buffer
    for (i = 0; i < bufnum; ++i) {
        memset(&v4l2_buf, 0, sizeof(v4l2_buf));
        v4l2_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        v4l2_buf.memory = V4L2_MEMORY_MMAP;
        v4l2_buf.index = i;
        // i 的缓冲区，得到其起始物理地址和大小
        ret = ioctl(fd, VIDIOC_QUERYBUF, &v4l2_buf);
        if (ret < 0) {
            LOGE("+++%d : VIDIOC_QUERYBUF failed\n", __LINE__);
            return -1;
        }
        buffers[i].length = v4l2_buf.length;

        /**
         * mmap将一个文件或者其它对象映射进内存
         * void* mmap(void* start,size_t length,int prot,int flags,int fd,off_t offset);
         * start：映射区的开始地址，设置为0时表示由系统决定映射区的起始地址。
         * length：映射区的长度。//长度单位是 以字节为单位，不足一内存页按一内存页处理
         * prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起
         *                                                  PROT_EXEC //页内容可以被执行
         *                                                  PROT_READ //页内容可以被读取
         *                                                  PROT_WRITE //页可以被写入
         *                                                  PROT_NONE //页不可访问
         * flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体
         *                                                  MAP_FIXED //使用指定的映射起始地址，
         *                                                  如果由start和len参数指定的内存区重叠于现存的映射空间，
         *                                                  重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。
         *                                                  并且起始地址必须落在页的边界上。
         *                                                  MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，
         *                                                  相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。
         *
         * fd：有效的文件描述词。一般是由open()函数返回，其值也可以设置为-1，此时需要指定flags参数中的MAP_ANON,表明进行的是匿名映射。
         * offset：被映射对象内容的起点。
         */
        if ((buffers[i].start = (char *) mmap(0, v4l2_buf.length,
                                              PROT_READ | PROT_WRITE, MAP_SHARED,
                                              fd, v4l2_buf.m.offset)) < 0) {
            LOGE("%d : mmap() failed", __LINE__);
            return -1;
        }
    }
    return 0;
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    streamon
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_streamon
        (JNIEnv *env, jclass obj) {
    int i;
    int ret;
    enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    // 把所需缓冲帧放入队列，并启动数据流
    for (i = 0; i < bufnum; ++i) {
        memset(&v4l2_buf, 0, sizeof(v4l2_buf));
        v4l2_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        v4l2_buf.memory = V4L2_MEMORY_MMAP;
        v4l2_buf.index = i;
        /**
         * 把缓冲帧放入缓冲队列
         *  VIDIOC_QBUF// 把帧放入队列
         *  VIDIOC_DQBUF// 从队列中取出帧
         */
        ret = ioctl(fd, VIDIOC_QBUF, &v4l2_buf);
        if (ret < 0) {
            LOGE("%d : VIDIOC_QBUF failed\n", __LINE__);
            return ret;
        }
    }
    /**
     * 启动 或 停止数据流 VIDIOC_STREAMON， VIDIOC_STREAMOFF　　
     * argp 为流类型指针，如V4L2_BUF_TYPE_VIDEO_CAPTURE.
     */
    ret = ioctl(fd, VIDIOC_STREAMON, &type);
    if (ret < 0) {
        LOGE("%d : VIDIOC_STREAMON failed\n", __LINE__);
        return ret;
    }
    return 0;
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    dqbuf
 * Signature: ([B)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_dqbuf
        (JNIEnv *env, jclass obj, jbyteArray videodata) {
    int ret;

    jbyte *data = (jbyte *) (*env)->GetByteArrayElements(env, videodata, 0);
    v4l2_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    v4l2_buf.memory = V4L2_MEMORY_MMAP;

    ret = ioctl(fd, VIDIOC_DQBUF, &v4l2_buf);
    if (ret < 0) {
        LOGE("%s : VIDIOC_DQBUF failed, dropped frame\n", __func__);
        return ret;
    }
    memcpy(data, buffers[v4l2_buf.index].start, buffers[v4l2_buf.index].length);
    (*env)->ReleaseByteArrayElements(env, videodata, data, 0);
    return v4l2_buf.index;
}


/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    yuvtorgb
 * Signature: ([B[BII)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_yuvtorgb
        (JNIEnv *env, jclass obj, jbyteArray yuvdata, jbyteArray rgbdata, jint dwidth,
         jint dheight) {
    jbyte *ydata = (jbyte *) (*env)->GetByteArrayElements(env, yuvdata, 0);
    jbyte *rdata = (jbyte *) (*env)->GetByteArrayElements(env, rgbdata, 0);
    AVFrame *rpicture = NULL;
    AVFrame *ypicture = NULL;
    struct SwsContext *swsctx = NULL;
    rpicture = av_frame_alloc();
    ypicture = av_frame_alloc();
    avpicture_fill((AVPicture *) rpicture, (uint8_t *) rdata, AV_PIX_FMT_RGB565, dwidth, dheight);
    avpicture_fill((AVPicture *) ypicture, (uint8_t *) ydata, AV_PIX_FMT_YUYV422, mwidth, mheight);
    swsctx = sws_getContext(mwidth, mheight, AV_PIX_FMT_YUYV422, dwidth, dheight, AV_PIX_FMT_RGB565,
                            SWS_BICUBIC, NULL, NULL, NULL);
    sws_scale(swsctx, (const uint8_t *const *) ypicture->data, ypicture->linesize, 0, mheight,
              rpicture->data, rpicture->linesize);
    sws_freeContext(swsctx);
    av_free(rpicture);
    av_free(ypicture);
    (*env)->ReleaseByteArrayElements(env, yuvdata, ydata, 0);
    (*env)->ReleaseByteArrayElements(env, rgbdata, rdata, 0);
    return 0;
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    qbuf
 * Signature: (I)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_qbuf
        (JNIEnv *env, jclass obj, jint index) {
    int ret;

    v4l2_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    v4l2_buf.memory = V4L2_MEMORY_MMAP;
    v4l2_buf.index = index;

    ret = ioctl(fd, VIDIOC_QBUF, &v4l2_buf);
    if (ret < 0) {
        LOGE("%s : VIDIOC_QBUF failed\n", __func__);
        return ret;
    }

    return 0;
}

AVCodecContext *pCodecCtx = NULL;
AVPacket avpkt;
FILE *video_file;
unsigned char *outbuf = NULL;
unsigned char *yuv420buf = NULL;
static int outsize = 0;

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    videoinit
 * Signature: ([B)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_videoinit
        (JNIEnv *env, jclass obj, jbyteArray filename) {
    LOGI("%s\n", __func__);
    AVCodec *pCodec = NULL;
    avcodec_register_all();
    pCodec = avcodec_find_encoder(AV_CODEC_ID_MPEG1VIDEO);
    if (pCodec == NULL) {
        LOGE("++++++++++++codec not found\n");
        return -1;
    }
    pCodecCtx = avcodec_alloc_context3(pCodec);
    if (pCodecCtx == NULL) {
        LOGE("++++++Could not allocate video codec context\n");
        return -1;
    }
    /* put sample parameters */
    pCodecCtx->bit_rate = 400000;
    /* resolution must be a multiple of two */
    pCodecCtx->width = mwidth;
    pCodecCtx->height = mheight;
    /* frames per second */
    pCodecCtx->time_base = (AVRational) {1, 25};
    pCodecCtx->gop_size = 10; /* emit one intra frame every ten frames */
    pCodecCtx->max_b_frames = 1;
    pCodecCtx->pix_fmt = AV_PIX_FMT_YUV420P;//AV_PIX_FMT_YUYV422;
    /* open it */
    if (avcodec_open2(pCodecCtx, pCodec, NULL) < 0) {
        LOGE("+++++++Could not open codec\n");
        return -1;
    }
    outsize = mwidth * mheight * 2;
    outbuf = malloc(outsize * sizeof(char));
    yuv420buf = malloc(outsize * sizeof(char));
    jbyte *filedir = (jbyte *) (*env)->GetByteArrayElements(env, filename, 0);
    if ((video_file = fopen(filedir, "wb")) == NULL) {
        LOGE("++++++++++++open %s failed\n", filedir);
        return -1;
    }
    (*env)->ReleaseByteArrayElements(env, filename, filedir, 0);
    return 1;
}
/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    videostart
 * Signature: ([B)I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_videostart
        (JNIEnv *env, jclass obj, jbyteArray yuvdata) {
    int frameFinished = 0, size = 0;
    jbyte *ydata = (jbyte *) (*env)->GetByteArrayElements(env, yuvdata, 0);
    AVFrame *yuv420pframe = NULL;
    AVFrame *yuv422frame = NULL;
    struct SwsContext *swsctx = NULL;
    yuv420pframe = av_frame_alloc();
    yuv422frame = av_frame_alloc();
    avpicture_fill((AVPicture *) yuv420pframe, (uint8_t *) yuv420buf, AV_PIX_FMT_YUV420P, mwidth,
                   mheight);
    avpicture_fill((AVPicture *) yuv422frame, (uint8_t *) ydata, AV_PIX_FMT_YUYV422, mwidth,
                   mheight);
    swsctx = sws_getContext(mwidth, mheight, AV_PIX_FMT_YUYV422, mwidth, mheight,
                            AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);
    sws_scale(swsctx, (const uint8_t *const *) yuv422frame->data, yuv422frame->linesize, 0, mheight,
              yuv420pframe->data, yuv420pframe->linesize);
    av_init_packet(&avpkt);
    size = avcodec_encode_video2(pCodecCtx, &avpkt, yuv420pframe, &frameFinished);
    if (size < 0) {
        LOGE("+++++Error encoding frame\n");
        return -1;
    }
    if (frameFinished)
        fwrite(avpkt.data, avpkt.size, 1, video_file);
    av_free_packet(&avpkt);
    sws_freeContext(swsctx);
    av_free(yuv420pframe);
    av_free(yuv422frame);
    (*env)->ReleaseByteArrayElements(env, yuvdata, ydata, 0);
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    videoclose
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_videoclose
        (JNIEnv *env, jclass obj) {
    fclose(video_file);
    avcodec_close(pCodecCtx);
    av_free(pCodecCtx);
    free(outbuf);
}

/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    streamoff
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_streamoff
        (JNIEnv *env, jclass obj) {
    enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    int ret;

    // 停止数据流
    ret = ioctl(fd, VIDIOC_STREAMOFF, &type);
    if (ret < 0) {
        LOGE("%s : VIDIOC_STREAMOFF failed\n", __func__);
        return ret;
    }

    return 0;
}
/*
 * Class:     com_jiangyt_library_libitop_UvcCamera
 * Method:    release
 * Signature: ()I
 */
JNIEXPORT jint JNICALL Java_com_jiangyt_library_libitop_UvcCamera_release
        (JNIEnv *env, jclass obj) {
    enum v4l2_buf_type type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    int ret;
    int i;

    ret = ioctl(fd, VIDIOC_STREAMOFF, &type);
    if (ret < 0) {
        LOGE("%s : VIDIOC_STREAMOFF failed\n", __func__);
        return ret;
    }

    for (i = 0; i < bufnum; i++) {
        // 断开映射
        ret = munmap(buffers[i].start, buffers[i].length);
        if (ret < 0) {
            LOGE("%s : munmap failed\n", __func__);
            return ret;
        }
    }
    free(buffers);
    close(fd);
    return 0;
}

